{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Propagación_error_varias_variables_v1_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"F9QIZFFX-UPy"},"source":["# Propagación del error para varias variables\n","\n","Material en construcción, Edgar Rueda, marzo 2021\n","\n","**Conocimientos previos recomendados**\n","- Concepto de error estándar\n","- Concepto de error en el error.\n","- Propagación del error en una variable.\n","\n","**Bibliografía**\n","- Hughes, I., & Hase, T. (2010). Measurements and their uncertainties: a practical guide to modern error analysis. Oxford University Press.\n","\n","- Lyons, L., & Louis, L. (1991). A practical guide to data analysis for physical science students. Cambridge University Press.\n","\n","- Squires, G. L. (2001). Practical physics. Cambridge university press."]},{"cell_type":"markdown","metadata":{"id":"BP6Qmow8_InW"},"source":["## 1. Variable indirecta dependiente de $n$ variables directas\n","A diferencia del caso con una sola  variable directa, ahora nuestra variable indirecta $Y$ depende de $n$ variables directas $X_i = x_{0i} \\pm \\Delta x_i$ de la forma $Y = y(X_1, X_2, ..., X_i, ...,X_n)$, donde pondremos como condición que dichas variables directas son independientes entre sí (no están correlacionadas).\n","\n","Una primera aproximación a este problema sería calcular todas las posibles combinaciones para encontrar los valores extremos, y a partir de esto determinar el rango de incertidumbre, como se observa en el siguiente ejemplo."]},{"cell_type":"markdown","metadata":{"id":"F3hlfCNXc_D2"},"source":["**Ejemplo**: se quiere determinar el error en la variable indirecta $Y = A/ B - C$, donde $A = 14 \\pm 8$, $B = 11 \\pm 7$, y $C = 23 \\pm 4$. Calculando todas las posibles combinaciones, y hallando los valores extremos, encontramos que el valor a reportar es $Y = -22 \\ ^{+8}_{-5}$.\n"]},{"cell_type":"code","metadata":{"id":"A3HkOs8N-H41","cellView":"form"},"source":["#@title código...\n","import numpy as np\n","def yfun(a,b,c):\n","  return a/b - c\n","\n","A = np.array([14,8])\n","B = np.array([11,7])\n","C = np.array([23,4])\n","\n","val0 = yfun(A[0],B[0],C[0])\n","#print('Valor central= = %f'%val0)\n","\n","valm = val0\n","valM = val0\n","\n","for aa in np.array([-A[1],A[1]]):\n","  for bb in np.array([-B[1],B[1]]):\n","    for cc in np.array([-C[1],C[1]]):\n","      val = yfun(A[0]+aa,B[0]+bb,C[0]+cc)\n","      if (val<valm): valm = val\n","      if (val>valM): valM = val\n","\n","#print('valor menor = %f'%valm)\n","#print('valor mayor = %f'%valM)\n","#print('Incertidumbre + = %f'%(valM-val0))\n","#print('Incertidumbre - = %f'%(val0-valm))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsktveJYgAIT"},"source":["No obstante, siendo coherentes con la forma como determinamos el error estándar a partir de determinar la varianza, que está relacionada con el valor esperado del cuadrado de la diferencia entre los valores y el valor central, y como hemos dicho que las variables directas son independientes, para determinar el error en la variable $Y$ seguiremos el procedimiento sugerido por Lyons (pág. 26):\n","\n","1. Calcule el valor central $Y_0 = y(x_{01},x_{02},...,x_{0n})$.\n","2. Calcule los $n$ valores $Y_{iM} = y(x_{01},x_{02},x_{0i} + \\Delta x_i,...,x_{0n})$\n","3. Obtenga el cuadrado del error estimado de las sumas $\\alpha_{Y_M}^2 = \\sum\\limits_{i=1}^n (Y_{iM} - Y_0)^2$\n","4. Calcule los $n$ valores $Y_{im} = y(x_{01},x_{02},x_{0i} - \\Delta x_i,...,x_{0n})$\n","3. Obtenga el cuadrado del error estimado de las restas $\\alpha_{Y_m}^2 = \\sum\\limits_{i=1}^n (Y_{im} - Y_0)^2$\n","\n","El valor a reportar será $Y = Y_0 \\ ^{+\\alpha_{Y_M}}_{-\\alpha_{Y_m}}$.\n","\n","**Nota**: cuando el error es asimétrico se debe tener precaución con la interpretación que se da del mismo en términos de confiabilidad, esto porque la asimetría indica que la distribución de la variable indirecta no es gaussiana, y la definición de confiabilidad la hicimos a partir de una distribución gaussiana.\n","\n","**Ejemplo**: Aplicando este procedimiento a los datos del ejemplo anterior obtenemos $Y = -22 \\ ^{+4}_{-5}$."]},{"cell_type":"code","metadata":{"cellView":"form","id":"QIXEZTsVdO90"},"source":["#@title Código:\n","fiM = np.array([yfun(A[0]+A[1],B[0],C[0]),yfun(A[0],B[0]+B[1],C[0]),yfun(A[0],B[0],C[0]+C[1])])\n","errfM = np.sqrt(np.sum((fiM-val0)**2))\n","fim = np.array([yfun(A[0]-A[1],B[0],C[0]),yfun(A[0],B[0]-B[1],C[0]),yfun(A[0],B[0],C[0]-C[1])])\n","errfm = np.sqrt(np.sum((fim-val0)**2))\n","#print('Error + = %f'%errfM)\n","#print('Error - = %f'%errfm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-SIqV4T-svuD"},"source":["## 2. Errores pequeños para una sola medida\n","Para el caso en que nuestras variables directas las obtuvimos a partir de una sola medida, pensemos ahora que tenemos errores pequeños que podemos tratar como infinitesimales y por lo tanto podemos hacer uso del cálculo diferencial para hallar el error. Como nuestras variables directas son independientes podemos tratar este problema vectorialmente pensando que las variables forman un espacio vectorial ortogonal tal que una distancia infinitesimal en dicho espacio se puede escribir como:\n","\n","$$\\delta \\mathbf{Y} = \\sum\\limits_{i=1}^n \\frac{\\partial y}{\\partial X_i} \\delta_{x_i} \\ \\mathbf{\\hat x_i} \\quad (1)$$\n","\n","donde $\\delta_{x_i}$ es el error pequeño de cada variable directa medida solo una vez, y $\\mathbf{\\hat x_i}$ es el vector unitario correspondiente a cada variable directa en el espacio vectorial. El error en la variable indirecta $Y$ corresponderá a la norma del vector infinitesimal de la ecuación 1:\n","\n","$$\\delta_Y = \\sqrt{\\delta\\mathbf{Y}\\cdot\\delta\\mathbf{Y}} = \\sqrt{\\sum\\limits_{i=1}^n \\bigg(\\frac{\\partial y}{\\partial X_i}\\bigg)^2 \\delta_{x_i}^2} \\quad (2) $$\n","\n","**Ejemplo**: Si aplicamos la ecuación 2 a los datos del ejemplo anterior obtenemos\n","\n","$$\\delta_Y^2 = \\bigg(\\frac{\\partial y}{\\partial A}\\bigg)^2 \\delta_A^2 + \\bigg(\\frac{\\partial y}{\\partial B}\\bigg)^2 \\delta_B^2 + \\bigg(\\frac{\\partial y}{\\partial C}\\bigg)^2 \\delta_C^2 $$\n","\n","$$\\delta_Y^2 = \\frac{1}{B^2} \\ \\delta_A^2 + \\frac{A^2}{B^4} \\ \\delta_B^2 + \\delta_C^2 $$\n","\n","$$\\delta_Y = 4.145$$\n","\n","Y por lo tanto el valor a reportar es $Y = -22 \\pm 4.$. Es de notar que al suponer los errores pequeños no dimos cuenta de la asimetría en el error."]},{"cell_type":"code","metadata":{"cellView":"form","id":"igR05vggebHi"},"source":["#@title Código:\n","alfaY = np.sqrt((1/B[0])**2*A[1]**2 + (A[0]/B[0]**2)**2*B[1]**2 + C[1]**2)\n","#print('Error variable Y = %f'%alfaY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccxTSWNL6wfA"},"source":["Si repetimos el ejemplo pero ahora con errores pequeños $A = 14 \\pm 2$, $B = 11 \\pm 7$, y $C = 23 \\pm 4$, encontramos los siguentes resultados: usando el procedimiento de Lyons $Y = -22 \\pm 2$, y usando el procedimiento con derivadas parciales $Y = -22 \\pm 2$. Vemos que ahora ambas formas dan el mismo resultado, pero es \"mucho más sencillo\" usando la forma diferencial.\n","\n","**Nota**: pongo entre comillas la expresión \"mucho más sencillo\" porque si las derivadas parciales son muy complejas ciertamente será más sencillo usar el procedimiento de Lyons."]},{"cell_type":"code","metadata":{"cellView":"form","id":"79c16MMN2LNl"},"source":["#@title Código:\n","A = np.array([14,2])\n","B = np.array([11,2])\n","C = np.array([23,2])\n","\n","val0 = yfun(A[0],B[0],C[0])\n","#print('Valor central= = %f'%val0)\n","\n","#print('\\nVarianza:')\n","fiM = np.array([yfun(A[0]+A[1],B[0],C[0]),yfun(A[0],B[0]+B[1],C[0]),yfun(A[0],B[0],C[0]+C[1])])\n","errfM = np.sqrt(np.sum((fiM-val0)**2))\n","fim = np.array([yfun(A[0]-A[1],B[0],C[0]),yfun(A[0],B[0]-B[1],C[0]),yfun(A[0],B[0],C[0]-C[1])])\n","errfm = np.sqrt(np.sum((fim-val0)**2))\n","#print('Error + = %f'%errfM)\n","#print('Error - = %f'%errfm)\n","\n","#print('\\nDiferencial:')\n","alfaY = np.sqrt((1/B[0])**2*A[1]**2 + (A[0]/B[0]**2)**2*B[1]**2 + C[1]**2)\n","#print('Error variable Y = %f'%alfaY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZkZZHRFHlFq"},"source":["## 3. Errores pequeños para varias medidas\n","Cuando nuestras variables directas fueron determinadas a partir de varias medidas tal que $X_i = x_{0i} \\pm \\alpha_{x_i}$, donde $\\alpha_{x_i}$ son los errores estándar de las variables directas, como dichas variables son independientes, es decir, no están correlacionadas, podemos reemplazar los errores estándar respectivos en la ecuación 2. El error de la variable indirecta será:\n","\n","$$\\alpha_Y = \\sqrt{\\sum\\limits_{i=1}^n \\bigg(\\frac{\\partial y}{\\partial X_i}\\bigg)^2 \\alpha_{x_i}^2} \\quad (3) $$\n","\n","Como en el caso de variables directas **independientes** las expresiones para los errores midiendo una vez o varias son los mismos, podremos combinar variables directas de una sola medida o de varias medidas en la misma expresión del error de la variable indirecta.\n","\n","**Nota**: una deducción más completa de la ecuación 3 para el caso de varias medidas la pueden encontrar en el libro de Squire (pág. 29)."]},{"cell_type":"code","metadata":{"id":"il0gYyNwjswg"},"source":[""],"execution_count":null,"outputs":[]}]}